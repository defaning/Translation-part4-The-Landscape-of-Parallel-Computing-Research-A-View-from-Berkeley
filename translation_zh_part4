4.0 硬件
现在，我们已经给出了对于图1左侧方框中关于并行计算的应用程序和darwf短板的观点，接下来准备检测探讨右边方框的部分：硬件。上面的第2章节章描述了关于半导体工艺当前以及未来的制约因素，但同时也提供了许多机会。
我们围绕30多年前首次用于描述计算机的三个组件的硬件部分进行了研究，它们分别是：处理器、内存和交换机交换[Bell and Newell 1970]。

4.1 处理器：小是而美
在诸如钢铁制造业等许多现代技术的发展中，我们可以观察到在很长的一段时期里，更大的等同于更好的。要辨认这些发展时期很简单：一个顶尖的工程示例仅仅只是只是被一个更大好的所取代。由于规模经济或其他经济因素的减少，这些技术的发展不可避免地发生了一个转折点转折，继而永远地改变了其发展的道路。我们认为通用微处理器的发展正在触及这样一个转折点。
第2部分中的第4条新CW（传统智慧）指出，我们可以成功设计和制造的模块尺寸正在缩小。而第2部分的第1条和第2条新CW指出，功率被证明是当前和未来几代处理单元的主要约束。为了支持这些说法，我们注意到，几个下一代处理器（例如Intel的Tejas Pentium 4处理器）都因为功耗问题被取消或重新定义了[Wolfe 2004]。即使是定位于“更高的时钟速度更周期越短越好”的Intel公司的代表也警告称，通过最大化时钟速度来实现性能最大化的传统方法已被推到极限[Borkar 1999] [Gelsinger 2001]。在本节中，我们将抛开转折点来问一个问题：什么处理器是构建未来多处理器系统的最佳构建模块？
用较小的处理器构建更小的处理模块来构造构建未来的微处理器系统有许多优点：
• 并行性的实现是一种实现性能高效的节能途径[Chandrakasan et al 1992]。
• 许多小型内核为并行代码提供了最高的单位面积性能。
• 大数量的小型处理部件能够更细粒度地执行动态电压伸缩和断电。
• 小型处理单元是一种经济的单元部件，在面临灾难性缺陷时易于关闭，并且在面对大参数变化时也更容易重新配置。Cisco Metro芯片[Eatherton 2005]为每个芯片增加了四个冗余处理器，而Sun以8-处理器设计的产量为基础，销售4-处理器、6-处理器或8-处理器版本的Niagara。据报道，图形处理器也正以这种方式使用冗余处理器，在索尼的Playstation 3游戏机中，8个协同处理器中只有7个使用了IBM Cell微处理器。
• 具有简单架构的小型处理元件更易于设计和进行功能验证。 尤其是比起乱序执行的复杂体系结构，它更适合于正式的验证技术。
• 单个的较小的硬件模块更加节能，其性能和功耗特性在现有的电子自动化设计流程中也更易于预测 [Sylvester and Keutzer 1998][Sylvester and Keutzer 2001] [Sylvester et al 1999]。
虽然上述观点表明我们应该考虑采用更小的处理器架构来实现我们的基本构建模块，但它们并不能准确指出哪种电路规模或处理器架构能够为我们提供最好的服务。 。我们认为，我们必须摆脱简单化的“更大即更好”的方法。但是，这也并不意味着“最小的是就是最好的”。

4.1.1 什么处理单元最合适？
确定最佳的处理单元将需要依赖于应用程序，部署环境，工作负荷，目标市场约束和制造技术等多元优化问题的解决方案或至少是近似的解决方案。然而，显而易见的是，性能和功耗之间的权衡对于当前和未来的多处理器系统的整个系统应用来说都是至关重要的。
区分能量（焦耳）和功率（焦耳秒或瓦特）是很重要的，功率是指消耗能量的速度。在一个设计中当中，每个任务消耗的能量通常是要被需要尽量最小化的度量，而峰值功耗则通常被视为设计约束。计算所使用的能量会影响移动设备的电池寿命以及为服务器群供电的成本。 。峰值功率决定了封装和冷却处理器的成本，并且这些成本将随着急剧上升的功率消耗而增长。必须限制芯片温度以避免过度的泄漏功率。 。由于电迁移和其他高温可靠性问题，高芯片温度还可能导致寿命缩短。对于风冷式服务器和台式机芯片来说，其峰值功耗的合理上限是150W，而对于笔记本电脑是40W，低成本低功耗的嵌入式应用是2W。
不同的应用程序在性能和能源消耗之间将进行不同的权衡。例如，许多实时任务（例如，在笔记本电脑上观看DVD电影）具有固定性能需求——寻求最低的能量实现。桌面处理器通常在最大的功率限制下寻求最高性能。请注意，如果设计的处理单元不能在耗尽预定可用的电力预算前，足够快地完成任务，那么在功率限制下，即使设计中的每个操作都消耗最少的能量，这个设计也可能无法实现最高的性能。
如果所有任务都是高度可并行化的并且硅片面积是空余的，那么我们会希望有让每个指令能耗最低的内核（SPEC Watt）。 然而，我们也需要较少的并行代码以及单位面积的高吞吐量来降低芯片成本。我们面临的挑战是在提高性能的同时，不会增加每次操作的能耗或硅片面积。
[Gonzalez and Horowitz 1996]研究了微体系结构对能耗和延迟的影响。使用能耗延迟产品（SPEC2  W）作为度量标准，作者确定，简单的流水线技术能显著利于解决延迟，同时只会一定程度上增加能耗。相反，超标量体系结构会对能耗延迟产品产生不利影响。额外硬件所需的功率开销并未超过其性能优势。指令级的并行性是有限的，所以试图通过广泛性和预测执行等技术来获得更好性能的微架构实现了适度的性能提升，但却牺牲了大量的面积和能耗开销。
许多研究人员[Hrishikesh等人2002] [Srinivasan等人2002] [Harstein和Puzak 2003] [Heo和Asanovic 2004]研究了微体系结构中管道阶段的最佳数量。这些结果在[Chinnery 2006]中进行了总结和审查。请注意，迄今为止，单处理器基准测试（如SPEC）已成为测量计算和能效的最常用基准。我们相信未来的基准测试集必须发展，以反映更具代表性的混合应用，包括基于13个小矮人的并行代码，以避免单线程性能的过度优化。由于上述结果依赖于工艺技术，逻辑系列，基准集和工作负载，因此很难将结果推广到我们的目的。然而， Horowitz [Horowitz 2006]，Paulin [Paulin 2006]等文献的综述以及我们自己的调查[Chong和Catanzaro 2006]显示出，对收集的现有体系结构的经验数据分析表明，具有有序执行的浅层流水线已被证明是具有最大面积和能效的。鉴于这些物理和微观架构的考虑，我们相信未来体系结构的高效构建块可能是简单的，包括适度流水线（5-9级）处理器，浮点单元，矢量和SIMD处理单元等。请注意，这些限制违背了使用最大可用处理器来简化并行编程的传统观点。

4.1.2 我们真的能在一块经济芯片上安装1000个内核吗？
未来基本处理器构建模块的大小和复杂性的显着降低意味着可以在单个裸片上经济地实现更多的内核; 此外，这个数字可以与每代硅片相提并论。例如，“manycore”级数很可能是128,256,512 ......内核，而不是在相同的半导体工艺时代下，当前的“multicore”计划中的2,4,8 ......内核。
强有力的经验证据表明，当30nm技术可用时，我们可以在芯片上实现1000个内核。（由于英特尔已经推出了45nm技术芯片，未来30nm并不遥远。）思科现今在其路由器中嵌入了一个网络处理器，其中包含以130nm技术实现的188个内核。 [Eatherton 2005]该芯片尺寸为18mm×18mm，在250MHz时钟频率下功耗为35W，每秒产生500亿条指令。 单个处理器内核是具有非常小的缓存的5级Tensilica处理器，每个内核的尺寸为0.5mm2。 大约三分之一的芯片是DRAM和特定目的的功能单元。简单地按照摩尔定律进行扩展，就可以得到45nm技术下的752个处理器和30nm技术下的1504个处理器。不幸的是，功耗可能不会随着尺寸的减小而减少，但是在突破桌面或服务器应用的150W限制之前，我们有足够的空间。 

4.1.3一种尺寸适合所有的吗是否有一种处理器适用于任何场合？
我们简要地考虑一下这个问题，即将来的多处理器是作为相同处理器的集合来构建，还是由不同的异构处理单元组装而成。 现有的嵌入式多处理器（例如Intel IXP处理器系列），在芯片上至少保留一个通用处理器，以支持各种内部管理功能，并为更一般的（例如Linux）操作系统提供基础硬件支持。 同样，IBM Cell也有一个通用处理器和八个定制处理单元。在芯片上保留更大的处理器可能有助于加快“固有顺序”代码段的运行或减少工作负载的线程数量[Kumar et al 2003]。
正如Amdahl在40年前观察到的那样，一个程序中较少并行的部分可能会限制并行计算机的性能[Amdahl 1967]。因此，在多核体系结构中拥有不同“大小”的处理器的一个原因，是通过减少运行较少并行代码所需的时间来提高并行速度。例如，假设在100处理器计算机上，一个程序有10%的时间没有加速。假定以两倍的速度运行顺序代码，由于更大的功耗预算，更大的缓存，更大的乘法器等等，单个处理器需要的资源是单核运行时所需资源的10倍，它值得吗？使用Amdahl定律[Hennessy和Patterson 2007]，与单个简单处理器相比，同构100简单处理器设计和异构91处理器设计的相对加速比为：
SpeedupHomogeneous = 1 （0.1 - 0.9  100）= 9.2倍
SpeedupHeterogeneous = 1 （0.1  2 - 0.9  90）= 16.7倍
在这个例子中，即使一个较大的单处理器需要10倍的资源来获得两倍的运行速度，它将比把它替换为10个更小的处理器更有价值。
异构处理器解决方案不仅可以帮助运用Amdahl定律，还可以在功耗、延迟和面积方面显示出优势。实现处理器异构性的好处，同时最小化软件的成本开发和芯片实现的一种方法，是令处理器指令集具有可配置性[Killian等人,2001]，但这需要对每种新设计实行定制以实现性能优势，而这对于大型市场来说仅在经济上是合理的。
另一种在同构实现结构中实现异构性的方法是在预定义的可重配置逻辑中实现定制的软处理器。然而，当前区域（40倍），功耗（10倍）和延迟（3倍）开销[Kuon和Rose,2006]似乎使这种方法对于通用处理而言过于昂贵。一种有前途的支持处理器异构性的方法是添加一个可重配置的协处理器作为一个单独的芯片[Hauser和Wawrzynek,1997] [Arnold,2005]。这消除了对新定制芯片的需求。目前的数据不足以确定这种方法来提供节能解决方案。
另一方面，单个复制处理单元具有许多优点，特别是它提供了易于实现的芯片和常规软件环境。在具有数千个线程的环境中管理加入异构性问题可能会引起难以解决的问题。
与异构多核的灵活性和软件优势相比，异构多核可能拥有的功耗和面积优势会胜出吗？或者说，未来的处理器能否像晶体管一样，可以编织成任意复杂电路的单个构建块？又或者说，处理器能否变得更像是一个标准单元库中的NAND门，成为数百个密切相关但独特的设备系列中的一个实例？在本节中，我们无法声称已经解决了这些问题。相反，我们的观点是解决这些问题肯定需要大量的研究和实验，对于这项研究的需求比业界的多核多处理器路线图更迫切。

4.2解放内存解除访存限制
在过去的几十年里，DRAM产业已经的发展大幅度降低了每GB单位内存的价格，从1980年的每GB的1千万一千万美元[Hennessy和Patterson,2007]降至现在的100（2006年底）的每GB一百美元。令人感慨遗憾的是，正如第2部分的CW＃8所指出的那样，访问主内存的处理器访存周期数也从1980年的几个处理器周期大幅增长到增至现在的数百个。同时几百个。此外，存储墙已成为获得良好性能的主要障碍（参见第八节图九）。Thomas Sterling在SC06会议上向专家小组成员提出这一针对性问题来表达这种担忧：“多核心最终是否会被存储墙扼杀？”[Sterling,2006]
好消息是，如果我们看一下DRAM芯片的内部，我们会看到许多独立的宽内存大位宽存储块。 [Patterson等1997]例如，一个512Mbit DRAM由数百个存储体块组成，每个存储体有数千位宽块的位宽达到几千位。 很显然，DRAM芯片内有巨大的潜在带宽等待被开发利用，而且DRAM芯片内部的存储器延迟显然要好于分立存储芯片互连上的单独芯片时的延迟。
在为并行计算硬件创建新的硬件基础时，我们不应该通过不能总假设主存必须位于是由分立DRAM芯片通过标准接口连接的单独DRAM芯片内来构成的，因为这会限制我们创新。新的封装技术，如3D堆叠技术，可能会大幅度增加提高访存带宽，减少处理器与DRAM之间的访存延迟和功耗。尽管在有几千个处理器和数百个DRAM存储体块的一般情况下我们无法避免全局通信，但一些某些重要的计算类几乎完全可以是访问本地存储器而且因此局部存储，因而可以受益于从创新的存储器设计中受益。
在进行内存中进行技术创新的另一个原因是越来越多的硬件成本正在从处理转向内存。 旧的Amdahl定律是指出，一个平衡的计算机系统每的处理能力每提升1 MIPS处理器性能就需要大约增加1 MB的主存容量[Hennessy和Patterson 2007]。
尽管DRAM容量与摩尔定律保持同步，在1980年至1992年期间每三年翻两番，但从1996年到2002年，速度降为每两年翻一倍的速度变慢。今天我们仍然使用2002年推出的512Mbit DRAM。多核的设计将在单个芯片中释放更多的MIPS。鉴于目前内存容量增长缓慢，这种MIPS爆发增长表明，未来将有更大意味着将来存储面积占硅片总面积的比例的系统芯片专用于内存会增大。

4.3互联网络互连网络
在物理硬件互连层面，多核最初采用了内核和高速缓存间的总线或交叉开关，但这种解决方案不能扩展到1000以上数以千计的核上。我们需要片上拓扑结构与系统尺寸成线性关系，以防止互连的复杂性过度复杂而占据多核系统更多的成本。可扩展的片上通信互连网络将借鉴了大规模分组交换网络的想法[Dally and Towles 2001]。 像IBM Cell这样投片生产的芯片实现已经，例如IBM Cell采用多个环形网络来互连芯片上的九个处理器，并使用软件管理的内存在内核之间进行通信，而不是使用传统的缓存一致性协议。
尽管已经已有对统计流量模型进行了进的研究来帮助完善片上网络设计[Soteriou et al 2006]，但我们相信对13个Dwarfs短板的研究可以为使我们洞察更广泛的应用提供更多下的通信拓扑结构和资源需求。基于对覆盖全部矮人短板的现有大量并行科学应用的通信需求的研究[Vetter and McCracken 2001] [Vetter and Yoo 2002] [Vetter and Meuller 2002] [Kamil et al 2005]，我们进行了对以下沟通片上通信需求观察进行探究，以开发更高效和按用户规格定制的解决方案：
•集体沟通汇聚通信需求与点对点需求有很大区别。 需要全局通信的集体汇聚通信倾向于涉及非常小的主要是延迟限制的消息。随着核心数量的增加，这些细粒度，小于缓存行大小的集体汇聚同步结构的重要性可能会增加。由于延迟提高可能比带宽缓慢得多（请参见第2节中的CW＃6），关注点分离意味着增加专用于集体的单独的延迟导向网络。他们已经出现在先前的MPP中。 [Hillis and Tucker 1993] [Scott 1996]作为最近的一个大规模示例，IBM BlueGene  L除了为点对点消息提供更高带宽的“Torus”互连外，还为集体提供了“树”网络。这种方法对于采用1000以上的内核芯片互连实现可能是有益的。
•大多数点对点消息的大小通常足够大，即使对于片上互连，它们仍然保持带宽限制。 因此，每个点对点消息都会优先选择通过互连的专用点对点路径，以最大限度地减少网络结构内争用的可能性。因此，虽然通信拓扑不需要非阻塞交叉开关，但片上网络应具有较高的总带宽，并支持将消息流准确映射到片上互连拓扑。
•这些研究表明，大多数点对点通信是稳定和稀疏的，并且主要是受带宽的限制。除了3D FFT（参见图2）之外，点对点消息传递需求倾向于通过完全连接的网络交换结构（例如交叉开关或胖树）仅使用一小部分可用通信路径。对于片上互连，考虑到资源需求规模为互连处理器内核数量的平方，对于大多数应用需求来说，非阻塞交叉开关可能会过度设计，否则将会浪费硅硅片面积。没有表现出“光谱”矮人短板的通信模式的应用，用于片上互连的较低互连拓扑可能会证明更多的空间和功率效率。
尽管通信模式被认为是稀疏的，但它们不一定同构于等同于低度固定拓扑互连，如环面，网格或超立方体。因此，为每个点对点消息传输分配专用路径并不是不能由任何固定级别的互连拓扑普遍简单解决。为此，你可能需要仔细安排作业，以便它们匹配互连结构的静态拓扑或，或是采用可重新配置以符合应用通信拓扑的互连结构。
迄今目前观察到的交流通信模式与潜在的沟通通信计算模式密切相关。只有考虑到13个小矮人短板，互连可能需要针对相对有限的一组通信模式。它还表明并且编程模型可能会提供更高层次的抽象来描述这些模式。
对于带宽绑定通信路径，我们希望采用一种方法来尽量减少交换机占用的表面积芯片面积，同时符合应用通信拓扑的需求。优化互连拓扑以满足应用需求的直接方法是使用电路交换机的交换来增强分组交换机交换，以重新配置交换机交换之间的布线拓扑以来满足应用通信需求，同时保持分组交换机提供的复用解复用能力。该问题的逆向依赖于软件来管理任务映射和任务迁移，以适应较低程度的静态互连拓扑。电路交换方法为重新配置互连拓扑提供了更快的方式，这对于具有快速变化自适应通信需求的应用而言可能非常重要。在这两种情况下，运行时性能监测系统（参见第4.6节），编译时间代码的仪器来推断通信拓扑需求或自动调谐器（见第6.1节）都将在推断最佳互连拓扑和通信时间表方面发挥重要作用。
可以使用较简单的电路交换来提供专用线路，以使互连适应运行时应用的通信模式。该问题的一种可能解决方案是打包开关将分组交换与光电路开关交换组合进行混合设计。[Kamil等人,2005] [Shalf等人,2005]。然而，在微观尺度上，包含能适应通信拓扑的电路开关交换的混合开关交换设计可能能够满足所有未来的并行应用。混合电路交换方法可以通过定制运行时重新配置互连拓扑来消除未使用的电路路径和交换容量，从而为许多核心多核处理器带来更简单和占用面积更高小的片上互连。

4.4通信原语
最初，的应用很可能将多核和众核芯片简单地视为传统的对称多处理器（SMP）。但是，芯片级多处理器（CMP）提供了与SMP完全不同的独特功能，并且而且它提供了一些重大的新机遇：
• CMP上的核心间带宽可能是SMP典型带宽的数倍，由此可以终止性能瓶颈。
• 核心间潜伏期远低于SMP系统的典型值（至少一个数量级）。
• CMP可以提供只在同一芯片上的核心之间进行操作的新的轻量级一致性和同步原语。这些栅栏的语义与我们在SMP上使用的语义完全不同，并且将以低得多的延迟进行操作。
如果我们简单地将多核芯片视为传统的SMP，或者更糟的是，甚至是通过移植MPI应用程序（参见第5节中的图7），那么我们可能会错过一些非常有趣的，可以利用这些新功能的新体系结构设计和算法设计的非常有趣的机会。

4.4.1一致性
常规SMP使用高速缓存一致性协议来提供内核之间的通信，并且在一致性方案之上建立互斥锁以提供同步。众所周知，标准一致性协议对于某些数据通信模式（例如生产者 - 消费者流量）是低效的，但这些低效率将这样的低效会随着CMP核心数量核数的增加、潜在核心带宽的巨大增加和提升以及延迟减少的降低而被放大。因此我们需要更灵活或甚至可重新配置的数据一致性方案来利用改进提升的带宽和减少降低的延迟。一个例子可能是例如大型的片上缓存，它们可以灵活地适应私有配置或共享配置。此外，由于实时嵌入式应用程序倾向于对存储器层次结构进行更直接的控制，因此所以可以从被配置为软件管理暂存器便笺存储器的片上存储中受益。

4.4.2使用锁进行同步
处理器间的同步可能是在改进性能和可编程性方面改进最具潜力的领域。处理器同步有两种类型互斥和生产者-消费者。为了相互排斥，一次只能有一个对于互斥而言，在众多竞争的并发活动被中，一次仅允许一个活动更新一些共享的可变状态，但通常情况下，顺序并不重要。 。对于生产者 - -消费者同步而言，消费者必须等到一直等待，直到生产者生成了所需的值。 为止。常规系统使用通过锁来实现上述两种类型的同步。 （使许多。（传统SMP中也通常通过锁来处理多消费者和多生产者同步的障碍也通常使用传统SMP上的锁来建立）。
众所周知，这些锁定方案很难编程，因为程序员必须记住将锁与每一个关键的数据结构关联起来，并且使用一个防死锁的锁定方案来访问这些锁。锁定方案本质上是不可兼容的，因此不能形成通用并行编程模型的基础。更糟的是，这些锁定方案是使用自旋旋转等待来实现的，这会将导致过度的一致性流量和浪费连贯的交通和处理器能力。 的浪费。尽管可以通过使用中断来避免自旋旋转等待，但当前操作系统的硬件间中断和上下文切换使得这在大多数情况下是不切实际的。

4.4.3使用事务内存进行同步
      互斥同步的一个可能的解决方案是使用事务存储器[Herlihy and Moss 1993]。 多个处理器推测性地更新在事务内部的推测更新共享内存，并且只会在事务成功完成而不与其他处理器冲突的情况下提交所有更新。 。否则，更新将被撤消并且执行回滚到事务的开始。 。事务模型实现了非阻塞互斥同步（在互斥锁或屏障上不存在阻塞
）[Rajwar and Goodman 2002]。 事务性内存简化了互斥，因为程序员不需要分配和使用显式的锁变量或担心死锁。
    事务的连贯性和一致性（TCC）计划[Kozyrakis and Olukotun 2005]提议全球应用事务来取代传统的缓存一致性协议，并且当消费者到达生产者之前，通过投机回滚来支持生产者 - -消费者同步。
事务性记忆内存是一个很有前途但仍很活跃的研究领域。目前的纯软件方案具有较高的执行时间开销，而仅纯硬件方案或缺乏一般通用语言支持所需的设施，或需要非常复杂的硬件。有些形式的某些混合硬件软件方案很可能会出现，但在对这种方案的功能需求进行充分理解之前，还需要更多的使用事务性内存的实践经验。

4.4.4在内存中使用全空位进行同步
      减少生产者-消费者同步的开销将将要允许更细粒度的并行化，从而在应用程序中增加提高可利用的并行性。早期的提案包括内存字节中的全空位，这些技术可能值得得在多核时代重新被审视[Alverson et al 1990] [Alverson et al 1999]。 全空位已被证明有助于实现高效的大规模并行图算法（对应于下面的“矮人”图），这对新兴的生物信息学，数据库和信息处理应用至关重要[Bader和Madduri2006]。 特别是值得注意的是，Jon Berry等人(Berry et al. 2006)最近的研究表明，在一个简单的4核处理器MTA上执行的图形处理算法运行的，为全空比特提供硬件支持，在的图形处理算法，它的性能优于2006年的Top500列表中，它的性能优于最快的系统——64k处理器的BGL系统。

4.4.5使用消息传递进行同步
共享内存是一种非常强大的机制，它支持灵活的匿名通信，而且它的单芯片CMP实现可以减少与多芯片SMP中共享内存相关的许多开销。 尽管如此，消息传递可能在多核CMP中在多核SMP的核心之间间的消息传递仍可能存在，因为消息将数据传输和同步结合在一起，这种形式的消息特别适合于生产者-消费者通信。

4.5可靠性
第二部分的CW＃3指出，下一代微处理器将面临更高的软件错误率和硬件错误率。 不可靠组件得到可靠系统的一种方式是空间或时间的冗余是从不可靠组件得到可靠系统的方法。 由于空间冗余意味着更高的硬件成本和更高的功耗，因此我们必须在多核设计中慎重使用冗余。 对任何具有唯一数据副本的内存使用单错误校正、双错误检测(SECDED)编码，并在任何仅具有可从其他地方检索的数据副本的内存中，使用奇偶校验来保护。，而违反这些准则的服务器则会出现可靠性问题 [Hennessy and Patterson 2007]. 
例如，如果L1数据高速缓存使用回写写入的L2高速缓存，则L1数据高速缓存只需要奇偶校验，而L2高速缓存需要SEC  DED。 SEC  DED的成本是字宽对数的函数，对于64位的数据来说，8位的SEC  DED的是非常合适的。 奇偶校验每个字节字节只需要一位。 因此，能源和硬件的成本适中。
大型机是可靠硬件设计的黄金标准，并且准则，而它们使用的技术之一是使用重复重传来传尝试克服软错误。例如，他们会在放弃并重新向操作系统声明发现错误之前，重试这个传输10次。尽管在每辆公共汽车上条总线都配备这样一种机制可能会很昂贵，但有一些地方某些场景可能是经济有效的。例如，我们认为多核的通用设计框架将是全局异步的，但是而每个模块是本地同步，的。可以通过单向链接和队列将这些较大的功能块连接在一起。，而将奇偶校验和有限的重传方案纳入此框架会使得实现相对容易。
还可以将“可靠性增强折叠”加入到包含的机制中以提高性能或简化编程。例如，上面的事务存储器（第4.4.3节）简化了并行编程，通过将所有内存事件回滚到事务的开始，以防错误地预测并行性来简化并行编程。这样的回滚机制可以被用来帮助解决软错误。虚拟机还可以通过在不同的虚拟机中运行不同的程序来帮助系统应对故障（参见第6.2节）。在硬件停止之前，虚拟机可以将应用程序从发生故障的处理器移动到多核芯片中的工作处理器。由于虚拟机提供的强大隔离性，虚拟机也可以帮助应对软件故障，从而使应用程序崩溃的可能性大大降低。
除了这些看似明显的要点之外，在多核时代的可靠性还有一些值得信赖开放的问题：
• 检查错误的正确粒度是什么？整个处理器，甚至到注册寄存器？
• 对于一个错误，它的正确答案处理方式是什么？重试或？还是拒绝将来去使用将有问题的组件？
• 错误有多严重？我们是否需要冗余线程才能对结果保持信心，还是需要足够的硬件冗余？

4.6性能和能量计数器
性能计数器最初是为帮助计算机架构师评估其设计而创建的。 由于他们它们的价值主要是内省，他们所以在发展过程中它们的优先级最低。鉴于这种观点和优先级，重要的性能事件的度量往往不准确或缺失是不足为奇甚至是缺失的：为什么只在对产品架构师有用的性能计数器中推迟产品的缺陷，延迟bug的产生？
摩尔定律和Memory Wall的结合导致使得架构师可以设计越来越复杂的机制，以并试图通过指令级并行和缓存提供提高性能。由于总目标是在不改变的情况下更快地运行标准程序，因此架构师并不知道性能计数器对于编译器编写者和程序员越来越重要而言，因为他们得了解如何使他们的程序运行得更快,所以他们越来越重视性能计数器，而架构师并没有注意到这一点。因此，历史上这种对性能计数器的傲慢态度成为了提供，使得性能方面计数器的责任落在了提供方，即使在连续处理器上也是如此。
提到并行编程（编译器和程序员明确负责性能），意味着性能计数器必须成为最高等级。除了监控传统的顺序处理器性能特性之外，新计数器还必须帮助解决高效并行编程的难题。
下面的7.2节列出了评估并行程序的效率度量标准，这表明性能计数器可以有利于多核架构获得成功：
- 为了最大限度地减少远程访问，除了传输本地访问和本地字节外，还要识别和计算远程访问的数量和移动的数据量。
- 为了平衡负载，识别和测量空闲时间与每个处理器的活动时间。
- 为了减少同步开销，识别和测量每个处理器同步花费的时间。
随着能源和能源日益重要，它们也需要进行测量。从能源和电力的角度来看，电路设计人员可以为重要模块创建焦耳计数器。在台式计算机上，主要的能源消费者是处理器，主存储器，高速缓存，内存控制器，网络控制器和网络接口卡。
鉴于基于焦耳和时间，我们可以计算瓦特。不幸的是，测量时间变得越来越复杂。由于时钟速率是固定的，因此处理器通常会对处理器时钟周期进行计数。为了节省能源和电力，一些处理器具有可调阈值电压和时钟频率。 因此，为了准确地测量时间，除了时钟周期计数器之外，我们现在需要“皮秒计数器”。
虽然性能和能量计数对于并行处理的成功至关重要，但而且好消息是它们相对比较容易地被包含。我们的主要观点是提高他们的优先级：如果程序员无法准确测量其影响，请不要在程序中包含对性能或能量有显着影响的功能。

